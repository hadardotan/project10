import os, os.path, re, sys
from JackAnalyzer import JackTokenizer as JackAnalyzer
from JackAnalyzer import JackGrammar as grammar

from xml.sax.saxutils import escape

# Effects the actual compilation output. Gets its input from a JackTokenizer
# and emits its parsed structure into an output file/stream. The output is
# generated by a series of compilexxx() routines, one for every syntactic
# element xxx of the Jack grammar. The contract between these routines is
# that each compilexxx() routine should read the syntactic construct xxx
# from the input, advance() the tokenizer exactly beyond xxx, and output
# the parsing of xxx. Thus, compilexxx()may only be called if indeed xxx
# is the next syntactic element of the input.


NEW_LINE = "\n"


class CompilationEngine(object):
    def __init__(self, input_file, output_file):
        """
        Creates a new compilation engine with the
        given input and output. The next routine
        called must be compileClass().
        :param input_file:
        """
        self.tokenizer = JackAnalyzer.JackTokenizer(input_file, output_file)
        self.input = input_file  # already open :)
        self.type_list = [grammar.K_INT, grammar.K_CHAR, grammar.K_BOOLEAN]
        self.output = output_file  # already open :)
        self.tokenizer.advance()

        self.compile_class()

    def tag(self, tagName):
        """
        :param tagName: name that will go in the tag
        :return: opening tag
        """
        return '<' + tagName + '> '

    def ctag(self, tagName):
        """
        :param tagName: name that will go in the tag
        :return: closing tag
        """
        return ' </' + tagName + '>'

    def get_text(self, line):
        """ Returns the text that's between an opening and closing tag within a line"""
        match = re.match(r'\>(\w*)\<', line)  # TODO useless?
        if match.group(1):
            return match.group(1)
        else:
            return "Illegal line"


    def compile_class(self):
        """
        Compiles a complete class.
        :return:
        """

        # <class>
        self.output.write(self.tag(grammar.K_CLASS) + NEW_LINE)
        # class
        if self.tokenizer.token_type() != grammar.KEYWORD:
            raise ValueError("No class found in the file")
        else:
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
            # add class to list of types
            self.type_list.append(self.tokenizer.current_value)

        # class Name
        self.tokenizer.advance()
        self.compile_identifier()

        # {
        self.tokenizer.advance()
        self.checkSymbol("{")

        # classVarDec*
        self.tokenizer.advance()
        if (self.tokenizer.current_value == grammar.K_STATIC) or (self.tokenizer.current_value == grammar.K_FIELD):
            while (self.compile_class_var_dec(False) is not False):
                self.tokenizer.advance()


        if (self.tokenizer.current_value == grammar.K_CONSTRUCTOR) or \
                (self.tokenizer.current_value == grammar.K_FUNCTION) or \
                (self.tokenizer.current_value == grammar.K_METHOD):
            # subroutineDec*
            while (self.compile_subroutine(False) is not False):
                self.tokenizer.advance()

        # }

        self.checkSymbol("}")

        # </class>
        self.output.write(self.ctag("class") + NEW_LINE)

    def compile_class_var_dec(self, raise_error=True):
        """
        Compiles a static declaration or a field
        declaration.
        :return:
        """



        # Check if there is a classVarDec

        # 'static' or 'field'
        if (self.tokenizer.current_value == grammar.K_STATIC) or (self.tokenizer.current_value == grammar.K_FIELD):
            # <classVarDec>
            self.output.write(self.tag("classVarDec") + NEW_LINE)

            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        else:
            if raise_error:
                raise ValueError("No 'static' or 'field' found")
            else:
                return False

        # type
        self.tokenizer.advance()
        self.compile_type(True)

        # varName
        self.tokenizer.advance()
        self.compile_identifier()

        # (',' varName)*
        self.tokenizer.advance()
        more_varName = True
        self.multiple_varNames(more_varName, False)

        while (more_varName):
            if self.tokenizer.current_value == ",":
                self.output.write(
                    self.tag(grammar.K_SYMBOL) + self.tokenizer.current_value + self.ctag(grammar.K_SYMBOL)
                    + NEW_LINE)
                self.tokenizer.advance()
                if self.tokenizer.token_type() == grammar.K_IDENTIFIER:
                    self.output.write(
                        self.tag(grammar.K_IDENTIFIER) + self.tokenizer.current_value + self.ctag(grammar.K_IDENTIFIER)
                        + NEW_LINE)
                    self.tokenizer.advance()
                else:
                    raise ValueError("No varName found")
            else:
                more_varName = False

        # ;
        self.checkSymbol(";")

        # </classVarDec>
        self.output.write(self.ctag("classVarDec") + NEW_LINE)

    def compile_identifier(self):

        if self.tokenizer.token_type() == grammar.IDENTIFIER:
            self.output.write(
                self.tag(grammar.K_IDENTIFIER) + self.tokenizer.identifier() + self.ctag(grammar.K_IDENTIFIER)
                + NEW_LINE)
        else:
            raise ValueError("No type found")

    def multiple_varNames(self, more_vars, type):
        """ Compiles all the variables (if there are).
            It is used to represent (',' varName)*
            :param more_vars True if there are more varriables, false otherwise
            :param type True if the format is (',' type varName), and False otherwise"""
        while (more_vars):
            # ','
            if self.tokenizer.current_value == ",":
                self.output.write(
                    self.tag(grammar.K_SYMBOL) + self.tokenizer.symbol() + self.ctag(grammar.K_SYMBOL)
                    + NEW_LINE)

                # varName
                self.tokenizer.advance()
                if self.tokenizer.token_type() == grammar.IDENTIFIER:
                    self.output.write(
                        self.tag(grammar.K_IDENTIFIER) + self.tokenizer.current_value + self.ctag(grammar.K_IDENTIFIER)
                        + NEW_LINE)
                    self.tokenizer.advance()
                else:
                    raise ValueError("No varName found")
            else:
                more_vars = False

    def compile_subroutine(self, raise_error=True):
        """
        Compiles a complete method, function, or constructor.
        :return:
        """

        # "constructor" or "function" or "method"
        if ((self.tokenizer.current_value == grammar.K_CONSTRUCTOR) or (
            self.tokenizer.current_value == grammar.K_FUNCTION)
            or (self.tokenizer.current_value == grammar.K_METHOD)):
            # <subroutineDec>
            self.output.write(self.tag("subroutineDec") + NEW_LINE)
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        else:
            if raise_error:
                raise ValueError("No keyword found in subroutine")
            else:
                return False

        # "void" or type
        self.tokenizer.advance()
        if (self.tokenizer.current_value == grammar.K_VOID) or (self.tokenizer.current_value in self.type_list) or \
            (self.tokenizer.token_type() == grammar.IDENTIFIER):
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        else:
            if raise_error:
                raise ValueError("No keyword found in subroutine")
            return False
        # subroutine name
        self.tokenizer.advance()
        self.compile_identifier()

        # (
        self.tokenizer.advance()
        self.checkSymbol("(")

        # parameterList
        self.compile_parameter_list()

        # )
        self.tokenizer.advance()
        self.checkSymbol(")")

        # subroutine body
        self.tokenizer.advance()
        self.compile_subroutineBody()

        # </subroutine>
        self.output.write(self.ctag("subroutineDec") + NEW_LINE)
        return True

    def compile_subroutineBody(self):
        """
        Compiles subroutine's body
        """
        # <subroutineBody>
        self.output.write(self.tag("subroutineBody") + NEW_LINE)

        # {
        self.checkSymbol("{")

        # varDecs*
        self.tokenizer.advance()
        more_vars = True

        while(more_vars):
            self.compile_var_dec(False)
            self.tokenizer.advance()

            if self.tokenizer.current_value != "var":
                more_vars = False

        # statements
        self.compile_statements()

        # }
        self.checkSymbol("}")

        # </subroutineBody>
        self.output.write(self.ctag("subroutineBody") + NEW_LINE)

    def compile_parameter_list(self):
        """
        Compiles a (possibly empty) parameter list,
        not including the enclosing “()”.

        :return:
        """
        # <parameters>
        self.output.write(self.tag("parameterList") + NEW_LINE)

        # ((type varName) (',' type varName)*)?
        self.compile_type(False)
        more_varName = True
        self.multiple_varNames(more_varName, True)

        # </parameters>
        self.output.write(self.ctag("parameterList") + NEW_LINE)

    def compile_var_dec(self, raise_error=True):
        """
        Compiles a var declaration.
        :param raise_error: raises error if True, returns otherwise
        :return:
        """
        # <varDec>
        self.output.write(self.tag("varDec") + NEW_LINE)

        # 'var'
        if self.tokenizer.current_value == grammar.K_VAR:
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        else:
            if raise_error:
                raise ValueError("No 'var' found")
            else:
                return

        # type
        self.tokenizer.advance()
        self.compile_type(True)

        # varName
        self.tokenizer.advance()
        self.compile_identifier()

        # (',' varName)*
        self.tokenizer.advance()
        more_varNames = True
        self.multiple_varNames(more_varNames, False)

        # ';'
        self.checkSymbol(";")

        # </varDec>
        self.output.write(self.ctag("varDec") + NEW_LINE)

    def compile_type(self, raise_error):
        """ Checks if the type of the current line is in the type_list and if that's the case, it
        writes it in the output
        :param raise_error: if true, raise value if no type is found. Otherwise, return."""


        if (self.tokenizer.current_value in self.type_list):
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        elif (self.tokenizer.token_type() == grammar.IDENTIFIER):
            self.output.write(
                self.tag(grammar.K_IDENTIFIER) + self.tokenizer.current_value + self.ctag(grammar.K_IDENTIFIER)
                + NEW_LINE)
        else:
            if raise_error:
                raise ValueError("No type found")
            else:
                return

    def compile_statements(self):
        """
        Compiles a sequence of statements, not
        including the enclosing “{}”.
        :return:
        """
        more_statements = True
        # <statements>
        self.output.write(self.tag("statements") + NEW_LINE)

        # (statement)*
        while (more_statements):
            if self.tokenizer.current_value == "if":
                self.compile_if()
                self.tokenizer.advance()

            elif self.tokenizer.current_value == "let":
                self.compile_let()
                self.tokenizer.advance()

            elif self.tokenizer.current_value == "while":
                self.compile_while()
                self.tokenizer.advance()

            elif self.tokenizer.current_value == "do":
                self.compile_do()
                self.tokenizer.advance()

            elif self.tokenizer.current_value == "return":
                self.compile_return()
                self.tokenizer.advance()
            else:
                more_statements = False

        # </statements>
        self.output.write(self.ctag("statements") + NEW_LINE)

    def compile_do(self):
        """
        Compiles a do statement
        :return:
        """
        # <doStatement>
        self.output.write(self.tag("doStatement") + NEW_LINE)

        # do
        if self.tokenizer.current_value == "do":
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)

        # subroutineCall
        self.tokenizer.advance()
        self.subroutineCall()

        # ;
        self.tokenizer.advance()
        self.checkSymbol(";")

        # </doStatement>
        self.output.write(self.ctag("doStatement") + NEW_LINE)

    def compile_let(self):
        """
        Compiles a let statement.
        """

        # <let>
        self.output.write(self.tag("letStatement") + NEW_LINE)
        # let
        if self.tokenizer.current_value == "let":
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
            # varName
            self.tokenizer.advance()
            self.compile_identifier()

            # [
            advance_token = False
            self.tokenizer.advance()
            check_expression = False
            if self.checkSymbol("[", False):
                check_expression = True
            if check_expression:
                # expression
                self.tokenizer.advance()
                self.compile_expression(True, True)
                # ]
                self.tokenizer.advance()
                self.checkSymbol("]")
                advance_token = True

            # =
            if (advance_token):
                self.tokenizer.advance()
            self.checkSymbol("=")

            # expression
            self.tokenizer.advance()
            self.compile_expression(True, True)

            # ;
            self.tokenizer.advance()
            self.checkSymbol(";")

        # </letStatement>
        self.output.write(self.ctag("letStatement") + NEW_LINE)

    def compile_while(self):
        """
        Compiles a while statement.
        :return:
        """
        # <whileStatement>
        self.output.write(self.tag("whileStatement") + NEW_LINE)

        # while
        if self.tokenizer.current_value == "while":
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)
        # (
        self.tokenizer.advance()
        self.checkSymbol("(")
        # expression
        self.tokenizer.advance()
        self.compile_expression()

        # )
        self.tokenizer.advance()
        self.checkSymbol(")")

        # {
        self.tokenizer.advance()
        self.checkSymbol("{")

        # statement
        self.tokenizer.advance()
        self.compile_statements()

        # }
        self.checkSymbol("}")

        # </whileStatement>
        self.output.write(self.ctag("whileStatement") + NEW_LINE)

    def compile_return(self):
        """
        Compiles a return statement.
        :return:
        """

        # <returnStatement>
        self.output.write(self.tag("returnStatement") + NEW_LINE)

        # return
        if self.tokenizer.current_value == "return":
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)

        # expression?
        if self.tokenizer.get_next()[1] != grammar.SYMBOL:
            self.tokenizer.advance()
            self.compile_expression(False)

        # ;
        self.checkSymbol(";")

        # </returnStatement>
        self.output.write(self.ctag("returnStatement") + NEW_LINE)

    def compile_if(self):
        """
        Compiles an if statement, possibly with a trailing else clause.
        :return:
        """
        # <ifStatement>
        self.output.write(self.tag("ifStatement") + NEW_LINE)

        # if
        if self.tokenizer.current_value == "if":
            self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                              + NEW_LINE)

        # (
        self.tokenizer.advance()
        self.checkSymbol("(")

        # expression
        self.tokenizer.advance()
        self.compile_expression(True, True)

        # )
        self.tokenizer.advance()
        self.checkSymbol(")")

        # {
        self.tokenizer.advance()
        self.checkSymbol("{")

        # statements
        self.tokenizer.advance()
        self.compile_statements()

        # }

        self.checkSymbol("}")

        # (else {statement})?
        else_param = False

        if self.tokenizer.get_next()[0] == "else":
            self.tokenizer.advance()
            if self.tokenizer.current_value == "else":
                self.output.write(self.tag(grammar.K_KEYWORD) + self.tokenizer.current_value + self.ctag(grammar.K_KEYWORD)
                                  + NEW_LINE)
                else_param = True
        if (else_param):
            # {
            self.tokenizer.advance()
            self.checkSymbol("{")

            # statement
            self.tokenizer.advance()
            self.compile_statements()

            # }
            self.checkSymbol("}")

        # </ifStatement>
        self.output.write(self.ctag("ifStatement") + NEW_LINE)

    def compile_expression(self, tags=True, term_tag=False, expression_lst=False):
        """
        Compiles an expression.
        :return:
        """

        if tags:
            # <expression>
            self.output.write(self.tag("expression") + NEW_LINE)

        expression_counter = 0

        # term
        if self.compile_term(False, True) is False:
            return False
        else:
            if expression_lst:
                return True
            self.compile_term()

        # (op term)*
        if self.tokenizer.get_next()[0] in grammar.operators:
            self.tokenizer.advance()
            self.checkSymbol(self.tokenizer.current_value)
            self.tokenizer.advance()
            self.compile_term()


        if tags:
            # </expression>
            self.output.write(self.ctag("expression") + NEW_LINE)

        return expression_counter

    def compile_term(self, tags=True, check=False):
        """
        Compiles a term. This routine is faced with a slight difficulty when
        trying to decide between some of the alternative parsing rules.
        Specifically, if the current token is an identifier, the routine must
        distinguish between a variable, an array entry, and a subroutine call.
        A single look-ahead token, which may be one of “[“, “(“, or “.”
        suffices to distinguish between the three possibilities.
        Any other token is not part of this term and should not be advanced
        over.
        :return:
        """

        if tags and (check is False):
            # <term>
            self.output.write(self.tag("term") + NEW_LINE)


        # Integer constant, String constant, keyword constant
        type = self.tokenizer.token_type()
        if (type == grammar.INT_CONST) or \
                (type == grammar.KEYWORD and self.tokenizer.keyword() in grammar.keyword_constant):
            if check:
                return True
            self.output.write(self.tag(grammar.tokens_types[type-1]) + self.tokenizer.current_value +
                              self.ctag(grammar.tokens_types[type-1]) + NEW_LINE)
        elif type == grammar.STRING_CONS:
            if check:
                return True
            self.output.write(self.tag(grammar.tokens_types[type - 1]) + self.tokenizer.string_val() +
                                  self.ctag(grammar.tokens_types[type - 1]) + NEW_LINE)

        # ( expression )
        elif self.tokenizer.current_value == "(":
            if check:
                return True
            self.checkSymbol("(")
            self.tokenizer.advance()
            self.compile_expression(True, True)
            self.tokenizer.advance()
            self.checkSymbol(")")

        # unaryOp term
        elif self.tokenizer.current_value in grammar.unaryOp:
            if check:
                return True
            self.checkSymbol(self.tokenizer.current_value)
            self.tokenizer.advance()
            self.compile_term()

        # varName ([ expression ])?
        elif type == grammar.IDENTIFIER:
            if check:
                return True
            if self.tokenizer.get_next()[0] == "[":
                self.compile_identifier()
                self.tokenizer.advance()

                if self.checkSymbol("[", False):
                    self.tokenizer.advance()
                    self.compile_expression()
                    self.tokenizer.advance()
                    self.checkSymbol("]")
            elif (self.tokenizer.get_next()[0] == "(") or (self.tokenizer.get_next()[0] == "."):
                # subroutineCall
                self.subroutineCall()
            else:
                self.output.write(self.tag(grammar.K_IDENTIFIER) + self.tokenizer.current_value +
                                  self.ctag(grammar.K_IDENTIFIER) + NEW_LINE)

        else:
            return False
        if tags and (check is False):
            # </term>
            self.output.write(self.ctag("term") + NEW_LINE)
        return True

    def compile_expression_list(self):
        """
        Compiles a (possibly empty) comma separated list of expressions.
        :return:
        """
        # <expressionList>
        self.output.write(self.tag("expressionList") + NEW_LINE)

        # expression?
        if self.compile_expression(False, False, True) is not False:
            # (',' expression)*
            self.compile_expression(True, True)
            self.tokenizer.advance()
            while self.tokenizer.current_value == ',':
                self.checkSymbol(",")
                # expression
                self.tokenizer.advance()
                self.compile_expression(True, True)
                self.tokenizer.advance()

        # </expressionList>
        self.output.write(self.tag("/expressionList") + NEW_LINE)


    def return_tag(self, input):
        """
        :param input: line within an XML file
        :return: the line's tag
        """
        match = re.match(r'\<(\w*)\>', input)
        if match.group(1):
            return match.group(1)
        else:
            return "Illegal line"

    def checkSymbol(self, symbol, raise_error=True):
        """ Check if the symbol is in the current line in the XML file"""
        if self.tokenizer.current_value == symbol:
            self.output.write(
                self.tag(grammar.K_SYMBOL) + self.tokenizer.symbol() + self.ctag(grammar.K_SYMBOL) + NEW_LINE)
            return True
        else:
            if raise_error:
                raise ValueError("No symbol " + symbol + " found")

    def subroutineCall(self):

        # (subroutineName ( expressionList )) OR ((className | varName).subroutineName (expressionList))

        if self.tokenizer.token_type() == grammar.IDENTIFIER:
            self.output.write(
                self.tag(grammar.K_IDENTIFIER) + self.tokenizer.current_value + self.ctag(grammar.K_IDENTIFIER) + NEW_LINE)
            self.tokenizer.advance()
            if self.checkSymbol("(", False):
                self.compile_expression_list()
                self.checkSymbol(")")
            elif self.checkSymbol("."):
                # subroutineName
                self.tokenizer.advance()
                if self.tokenizer.token_type() == grammar.IDENTIFIER:
                    self.output.write(
                        self.tag(grammar.K_IDENTIFIER) + self.tokenizer.identifier() + self.ctag(
                            grammar.K_IDENTIFIER) + NEW_LINE)
                    # (
                self.tokenizer.advance()
                self.checkSymbol("(")
                # expressionList
                self.tokenizer.advance()
                self.compile_expression_list()
                # )
                self.checkSymbol(")")




